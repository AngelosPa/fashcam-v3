{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Final Model \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TensorFlow and tf.keras\n",
                "import tensorflow as tf\n",
                "# recommended models\n",
                "from keras.applications import vgg16\n",
                "from keras.applications.vgg19 import VGG19\n",
                "from keras.applications import ResNet50\n",
                "from tensorflow.keras.utils import load_img, img_to_array\n",
                "from keras.applications.imagenet_utils import preprocess_input\n",
                "from sklearn.metrics.pairwise import cosine_similarity\n",
                "from tensorflow.keras.models import Sequential, model_from_json\n",
                "from sklearn.model_selection import train_test_split\n",
                "from keras.models import Model\n",
                "from keras.layers import Dense, GlobalAveragePooling2D\n",
                "import keras\n",
                "\n",
                "#CNN Model\n",
                "from tensorflow.keras.models import Sequential\n",
                "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Flatten, Dense, Dropout\n",
                "from tensorflow.keras.optimizers import Adam\n",
                "from tensorflow.keras.callbacks import ModelCheckpoint\n",
                "\n",
                "import datetime\n",
                "# from tensorflow.keras.callbacks import TensorBoard\n",
                "from keras.utils import to_categorical\n",
                "#import resnet50\n",
                "# Helper libraries\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "# get the array with the class names from the folder \n",
                "# read foldernames\n",
                "import os\n",
                "import glob\n",
                "import cv2\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "# read all the paths from the folder\n",
                "def get_paths(folder):\n",
                "    paths = []\n",
                "    for root, dirs, files in os.walk(folder):\n",
                "        for file in files:\n",
                "            # if file.endswith(\".jpg\"):\n",
                "            paths.append(os.path.join(root, file))\n",
                "    return paths"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "shop_images = get_paths(\n",
                "    r'C:\\Users\\mrpal\\OneDrive\\Desktop\\WBS\\fashcam\\asos')\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## function that loads all models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "from keras.applications.vgg19 import VGG19\n",
                "\n",
                "\n",
                "def get_models():\n",
                "  # load the vgg models\n",
                "  vgg16_model = vgg16.VGG16(weights='imagenet')\n",
                "  vgg19_model = VGG19(weights='imagenet', include_top=False)\n",
                "  # remove the last layers in order to get features instead of predictions\n",
                "  feat_extractor_vgg19 = Model(inputs=vgg19_model.input,\n",
                "                               outputs=vgg19_model.get_layer(\"block5_pool\").output)\n",
                "  feat_extractor = Model(inputs=vgg16_model.input,\n",
                "                         outputs=vgg16_model.get_layer(\"fc2\").output)\n",
                "  # get the model with the last layer in order to get predictions\n",
                "  classifier = Model(inputs=vgg16_model.input,\n",
                "                     outputs=vgg16_model.get_layer(\"predictions\").output)\n",
                "  # print the layers of the CNN\n",
                "  feat_extractor.summary()\n",
                "  # feat_extractor_vgg19.summary()\n",
                "  classifier.summary()\n",
                "  return feat_extractor, classifier, feat_extractor_vgg19\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Model: \"model_1\"\n",
                        "_________________________________________________________________\n",
                        " Layer (type)                Output Shape              Param #   \n",
                        "=================================================================\n",
                        " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
                        "                                                                 \n",
                        " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
                        "                                                                 \n",
                        " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
                        "                                                                 \n",
                        " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
                        "                                                                 \n",
                        " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
                        "                                                                 \n",
                        " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
                        "                                                                 \n",
                        " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
                        "                                                                 \n",
                        " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
                        "                                                                 \n",
                        " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
                        "                                                                 \n",
                        " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
                        "                                                                 \n",
                        " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
                        "                                                                 \n",
                        " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
                        "                                                                 \n",
                        " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
                        "                                                                 \n",
                        " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
                        "                                                                 \n",
                        " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
                        "                                                                 \n",
                        " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
                        "                                                                 \n",
                        " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
                        "                                                                 \n",
                        " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
                        "                                                                 \n",
                        " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
                        "                                                                 \n",
                        " flatten (Flatten)           (None, 25088)             0         \n",
                        "                                                                 \n",
                        " fc1 (Dense)                 (None, 4096)              102764544 \n",
                        "                                                                 \n",
                        " fc2 (Dense)                 (None, 4096)              16781312  \n",
                        "                                                                 \n",
                        "=================================================================\n",
                        "Total params: 134,260,544\n",
                        "Trainable params: 134,260,544\n",
                        "Non-trainable params: 0\n",
                        "_________________________________________________________________\n",
                        "Model: \"model_2\"\n",
                        "_________________________________________________________________\n",
                        " Layer (type)                Output Shape              Param #   \n",
                        "=================================================================\n",
                        " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
                        "                                                                 \n",
                        " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
                        "                                                                 \n",
                        " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
                        "                                                                 \n",
                        " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
                        "                                                                 \n",
                        " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
                        "                                                                 \n",
                        " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
                        "                                                                 \n",
                        " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
                        "                                                                 \n",
                        " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
                        "                                                                 \n",
                        " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
                        "                                                                 \n",
                        " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
                        "                                                                 \n",
                        " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
                        "                                                                 \n",
                        " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
                        "                                                                 \n",
                        " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
                        "                                                                 \n",
                        " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
                        "                                                                 \n",
                        " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
                        "                                                                 \n",
                        " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
                        "                                                                 \n",
                        " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
                        "                                                                 \n",
                        " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
                        "                                                                 \n",
                        " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
                        "                                                                 \n",
                        " flatten (Flatten)           (None, 25088)             0         \n",
                        "                                                                 \n",
                        " fc1 (Dense)                 (None, 4096)              102764544 \n",
                        "                                                                 \n",
                        " fc2 (Dense)                 (None, 4096)              16781312  \n",
                        "                                                                 \n",
                        " predictions (Dense)         (None, 1000)              4097000   \n",
                        "                                                                 \n",
                        "=================================================================\n",
                        "Total params: 138,357,544\n",
                        "Trainable params: 138,357,544\n",
                        "Non-trainable params: 0\n",
                        "_________________________________________________________________\n",
                        "Model: \"model_4\"\n",
                        "_________________________________________________________________\n",
                        " Layer (type)                Output Shape              Param #   \n",
                        "=================================================================\n",
                        " input_3 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
                        "                                                                 \n",
                        " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
                        "                                                                 \n",
                        " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
                        "                                                                 \n",
                        " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
                        "                                                                 \n",
                        " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
                        "                                                                 \n",
                        " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
                        "                                                                 \n",
                        " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
                        "                                                                 \n",
                        " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
                        "                                                                 \n",
                        " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
                        "                                                                 \n",
                        " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
                        "                                                                 \n",
                        " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
                        "                                                                 \n",
                        " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
                        "                                                                 \n",
                        " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
                        "                                                                 \n",
                        " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
                        "                                                                 \n",
                        " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
                        "                                                                 \n",
                        " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
                        "                                                                 \n",
                        " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
                        "                                                                 \n",
                        " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
                        "                                                                 \n",
                        " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
                        "                                                                 \n",
                        " flatten (Flatten)           (None, 25088)             0         \n",
                        "                                                                 \n",
                        " fc1 (Dense)                 (None, 4096)              102764544 \n",
                        "                                                                 \n",
                        " fc2 (Dense)                 (None, 4096)              16781312  \n",
                        "                                                                 \n",
                        "=================================================================\n",
                        "Total params: 134,260,544\n",
                        "Trainable params: 134,260,544\n",
                        "Non-trainable params: 0\n",
                        "_________________________________________________________________\n",
                        "Model: \"model_5\"\n",
                        "_________________________________________________________________\n",
                        " Layer (type)                Output Shape              Param #   \n",
                        "=================================================================\n",
                        " input_3 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
                        "                                                                 \n",
                        " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
                        "                                                                 \n",
                        " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
                        "                                                                 \n",
                        " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
                        "                                                                 \n",
                        " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
                        "                                                                 \n",
                        " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
                        "                                                                 \n",
                        " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
                        "                                                                 \n",
                        " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
                        "                                                                 \n",
                        " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
                        "                                                                 \n",
                        " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
                        "                                                                 \n",
                        " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
                        "                                                                 \n",
                        " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
                        "                                                                 \n",
                        " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
                        "                                                                 \n",
                        " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
                        "                                                                 \n",
                        " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
                        "                                                                 \n",
                        " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
                        "                                                                 \n",
                        " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
                        "                                                                 \n",
                        " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
                        "                                                                 \n",
                        " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
                        "                                                                 \n",
                        " flatten (Flatten)           (None, 25088)             0         \n",
                        "                                                                 \n",
                        " fc1 (Dense)                 (None, 4096)              102764544 \n",
                        "                                                                 \n",
                        " fc2 (Dense)                 (None, 4096)              16781312  \n",
                        "                                                                 \n",
                        " predictions (Dense)         (None, 1000)              4097000   \n",
                        "                                                                 \n",
                        "=================================================================\n",
                        "Total params: 138,357,544\n",
                        "Trainable params: 138,357,544\n",
                        "Non-trainable params: 0\n",
                        "_________________________________________________________________\n",
                        "Model: \"model_7\"\n",
                        "_________________________________________________________________\n",
                        " Layer (type)                Output Shape              Param #   \n",
                        "=================================================================\n",
                        " input_5 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
                        "                                                                 \n",
                        " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
                        "                                                                 \n",
                        " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
                        "                                                                 \n",
                        " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
                        "                                                                 \n",
                        " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
                        "                                                                 \n",
                        " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
                        "                                                                 \n",
                        " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
                        "                                                                 \n",
                        " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
                        "                                                                 \n",
                        " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
                        "                                                                 \n",
                        " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
                        "                                                                 \n",
                        " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
                        "                                                                 \n",
                        " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
                        "                                                                 \n",
                        " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
                        "                                                                 \n",
                        " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
                        "                                                                 \n",
                        " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
                        "                                                                 \n",
                        " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
                        "                                                                 \n",
                        " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
                        "                                                                 \n",
                        " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
                        "                                                                 \n",
                        " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
                        "                                                                 \n",
                        " flatten (Flatten)           (None, 25088)             0         \n",
                        "                                                                 \n",
                        " fc1 (Dense)                 (None, 4096)              102764544 \n",
                        "                                                                 \n",
                        " fc2 (Dense)                 (None, 4096)              16781312  \n",
                        "                                                                 \n",
                        "=================================================================\n",
                        "Total params: 134,260,544\n",
                        "Trainable params: 134,260,544\n",
                        "Non-trainable params: 0\n",
                        "_________________________________________________________________\n",
                        "Model: \"model_8\"\n",
                        "_________________________________________________________________\n",
                        " Layer (type)                Output Shape              Param #   \n",
                        "=================================================================\n",
                        " input_5 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
                        "                                                                 \n",
                        " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
                        "                                                                 \n",
                        " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
                        "                                                                 \n",
                        " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
                        "                                                                 \n",
                        " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
                        "                                                                 \n",
                        " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
                        "                                                                 \n",
                        " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
                        "                                                                 \n",
                        " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
                        "                                                                 \n",
                        " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
                        "                                                                 \n",
                        " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
                        "                                                                 \n",
                        " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
                        "                                                                 \n",
                        " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
                        "                                                                 \n",
                        " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
                        "                                                                 \n",
                        " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
                        "                                                                 \n",
                        " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
                        "                                                                 \n",
                        " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
                        "                                                                 \n",
                        " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
                        "                                                                 \n",
                        " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
                        "                                                                 \n",
                        " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
                        "                                                                 \n",
                        " flatten (Flatten)           (None, 25088)             0         \n",
                        "                                                                 \n",
                        " fc1 (Dense)                 (None, 4096)              102764544 \n",
                        "                                                                 \n",
                        " fc2 (Dense)                 (None, 4096)              16781312  \n",
                        "                                                                 \n",
                        " predictions (Dense)         (None, 1000)              4097000   \n",
                        "                                                                 \n",
                        "=================================================================\n",
                        "Total params: 138,357,544\n",
                        "Trainable params: 138,357,544\n",
                        "Non-trainable params: 0\n",
                        "_________________________________________________________________\n"
                    ]
                }
            ],
            "source": [
                "feat_extractor = get_models()[0]\n",
                "classifier = get_models()[1]\n",
                "feat_extractor_vgg19 = get_models()[2]\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### function that uses resnet to predict the class and the sparse matrix of image given"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                " ResNet-50 is 50 layers deep and is trained on a million images of 1000 categories from the ImageNet database.\n",
                " the model has over 23 million trainable parameters"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "from tensorflow.keras.applications.resnet50 import ResNet50\n",
                "from tensorflow.keras.preprocessing import image\n",
                "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
                "\n",
                "\n",
                "def get_prediction_resnet(img_path):\n",
                "\n",
                "    # Load the pre-trained ResNet50 model, with the top layer removed\n",
                "    model = ResNet50(weights='imagenet', include_top=True)\n",
                "\n",
                "    # Load an image to use for prediction\n",
                "    img = load_img(img_path, target_size=(224, 224))\n",
                "    x = img_to_array(img)\n",
                "    x = np.expand_dims(x, axis=0)\n",
                "    x = preprocess_input(x)\n",
                "\n",
                "    # Get the predictions from the model\n",
                "    features = model.predict(x)\n",
                "\n",
                "    # Print the top 5 predictions\n",
                "    predictions = decode_predictions(features, top=2)\n",
                "    # for p in predictions[0]:\n",
                "    #     print(f\"Class: {p[1]}, Probability: {p[2]:.2f}\")\n",
                "    propability = predictions[0][0][2]\n",
                "    return predictions[0][0], propability\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "image_names = os.listdir('asos/only')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "1/1 [==============================] - 3s 3s/step\n",
                        "1/1 [==============================] - 4s 4s/step\n",
                        "1/1 [==============================] - 4s 4s/step\n",
                        "1/1 [==============================] - 4s 4s/step\n",
                        "1/1 [==============================] - 3s 3s/step\n",
                        "1/1 [==============================] - 4s 4s/step\n"
                    ]
                },
                {
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "Cell \u001b[1;32mIn [12], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m label \u001b[39m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(image_names[:\u001b[39m10\u001b[39m])):\n\u001b[1;32m----> 4\u001b[0m     get_prediction_resnet(\u001b[39m'\u001b[39;49m\u001b[39masos/only/\u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39m+\u001b[39;49m image_names[i])\n\u001b[0;32m      5\u001b[0m     label\u001b[39m.\u001b[39mappend(get_prediction_resnet(\u001b[39m'\u001b[39m\u001b[39masos/only/\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m image_names[i])[\u001b[39m0\u001b[39m])\n",
                        "Cell \u001b[1;32mIn [6], line 9\u001b[0m, in \u001b[0;36mget_prediction_resnet\u001b[1;34m(img_path)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_prediction_resnet\u001b[39m(img_path):\n\u001b[0;32m      7\u001b[0m \n\u001b[0;32m      8\u001b[0m     \u001b[39m# Load the pre-trained ResNet50 model, with the top layer removed\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m     model \u001b[39m=\u001b[39m ResNet50(weights\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mimagenet\u001b[39;49m\u001b[39m'\u001b[39;49m, include_top\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     11\u001b[0m     \u001b[39m# Load an image to use for prediction\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     img \u001b[39m=\u001b[39m load_img(img_path, target_size\u001b[39m=\u001b[39m(\u001b[39m224\u001b[39m, \u001b[39m224\u001b[39m))\n",
                        "File \u001b[1;32mc:\\Users\\mrpal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\applications\\resnet.py:521\u001b[0m, in \u001b[0;36mResNet50\u001b[1;34m(include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs)\u001b[0m\n\u001b[0;32m    518\u001b[0m     x \u001b[39m=\u001b[39m stack1(x, \u001b[39m256\u001b[39m, \u001b[39m6\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mconv4\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    519\u001b[0m     \u001b[39mreturn\u001b[39;00m stack1(x, \u001b[39m512\u001b[39m, \u001b[39m3\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mconv5\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 521\u001b[0m \u001b[39mreturn\u001b[39;00m ResNet(\n\u001b[0;32m    522\u001b[0m     stack_fn,\n\u001b[0;32m    523\u001b[0m     \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    524\u001b[0m     \u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    525\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mresnet50\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    526\u001b[0m     include_top,\n\u001b[0;32m    527\u001b[0m     weights,\n\u001b[0;32m    528\u001b[0m     input_tensor,\n\u001b[0;32m    529\u001b[0m     input_shape,\n\u001b[0;32m    530\u001b[0m     pooling,\n\u001b[0;32m    531\u001b[0m     classes,\n\u001b[0;32m    532\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    533\u001b[0m )\n",
                        "File \u001b[1;32mc:\\Users\\mrpal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\applications\\resnet.py:238\u001b[0m, in \u001b[0;36mResNet\u001b[1;34m(stack_fn, preact, use_bias, model_name, include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, **kwargs)\u001b[0m\n\u001b[0;32m    231\u001b[0m         file_hash \u001b[39m=\u001b[39m WEIGHTS_HASHES[model_name][\u001b[39m1\u001b[39m]\n\u001b[0;32m    232\u001b[0m     weights_path \u001b[39m=\u001b[39m data_utils\u001b[39m.\u001b[39mget_file(\n\u001b[0;32m    233\u001b[0m         file_name,\n\u001b[0;32m    234\u001b[0m         BASE_WEIGHTS_PATH \u001b[39m+\u001b[39m file_name,\n\u001b[0;32m    235\u001b[0m         cache_subdir\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmodels\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    236\u001b[0m         file_hash\u001b[39m=\u001b[39mfile_hash,\n\u001b[0;32m    237\u001b[0m     )\n\u001b[1;32m--> 238\u001b[0m     model\u001b[39m.\u001b[39;49mload_weights(weights_path)\n\u001b[0;32m    239\u001b[0m \u001b[39melif\u001b[39;00m weights \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    240\u001b[0m     model\u001b[39m.\u001b[39mload_weights(weights)\n",
                        "File \u001b[1;32mc:\\Users\\mrpal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
                        "File \u001b[1;32mc:\\Users\\mrpal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:3036\u001b[0m, in \u001b[0;36mModel.load_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[0;32m   3032\u001b[0m             hdf5_format\u001b[39m.\u001b[39mload_weights_from_hdf5_group_by_name(\n\u001b[0;32m   3033\u001b[0m                 f, \u001b[39mself\u001b[39m, skip_mismatch\n\u001b[0;32m   3034\u001b[0m             )\n\u001b[0;32m   3035\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 3036\u001b[0m             hdf5_format\u001b[39m.\u001b[39;49mload_weights_from_hdf5_group(f, \u001b[39mself\u001b[39;49m)\n\u001b[0;32m   3038\u001b[0m \u001b[39m# Perform any layer defined finalization of the layer state.\u001b[39;00m\n\u001b[0;32m   3039\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n",
                        "File \u001b[1;32mc:\\Users\\mrpal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\saving\\legacy\\hdf5_format.py:853\u001b[0m, in \u001b[0;36mload_weights_from_hdf5_group\u001b[1;34m(f, model)\u001b[0m\n\u001b[0;32m    846\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    847\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mWeight count mismatch for top-level weights when loading \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    848\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mweights from file. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    849\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel expects \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(symbolic_weights)\u001b[39m}\u001b[39;00m\u001b[39m top-level weight(s). \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    850\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mReceived \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(weight_values)\u001b[39m}\u001b[39;00m\u001b[39m saved top-level weight(s)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    851\u001b[0m         )\n\u001b[0;32m    852\u001b[0m     weight_value_tuples \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(symbolic_weights, weight_values)\n\u001b[1;32m--> 853\u001b[0m backend\u001b[39m.\u001b[39;49mbatch_set_value(weight_value_tuples)\n\u001b[0;32m    855\u001b[0m \u001b[39m# Perform any layer defined finalization of the layer state.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39m_flatten_layers():\n",
                        "File \u001b[1;32mc:\\Users\\mrpal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
                        "File \u001b[1;32mc:\\Users\\mrpal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
                        "File \u001b[1;32mc:\\Users\\mrpal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\backend.py:4302\u001b[0m, in \u001b[0;36mbatch_set_value\u001b[1;34m(tuples)\u001b[0m\n\u001b[0;32m   4300\u001b[0m \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mexecuting_eagerly() \u001b[39mor\u001b[39;00m tf\u001b[39m.\u001b[39minside_function():\n\u001b[0;32m   4301\u001b[0m     \u001b[39mfor\u001b[39;00m x, value \u001b[39min\u001b[39;00m tuples:\n\u001b[1;32m-> 4302\u001b[0m         x\u001b[39m.\u001b[39;49massign(np\u001b[39m.\u001b[39;49masarray(value, dtype\u001b[39m=\u001b[39;49mdtype_numpy(x)))\n\u001b[0;32m   4303\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   4304\u001b[0m     \u001b[39mwith\u001b[39;00m get_graph()\u001b[39m.\u001b[39mas_default():\n",
                        "File \u001b[1;32mc:\\Users\\mrpal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:943\u001b[0m, in \u001b[0;36mBaseResourceVariable.assign\u001b[1;34m(self, value, use_locking, name, read_value)\u001b[0m\n\u001b[0;32m    941\u001b[0m   validate_shape \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_shape \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shape\u001b[39m.\u001b[39mis_fully_defined()\n\u001b[0;32m    942\u001b[0m   kwargs[\u001b[39m\"\u001b[39m\u001b[39mvalidate_shape\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m validate_shape\n\u001b[1;32m--> 943\u001b[0m assign_op \u001b[39m=\u001b[39m gen_resource_variable_ops\u001b[39m.\u001b[39massign_variable_op(\n\u001b[0;32m    944\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle, value_tensor, name\u001b[39m=\u001b[39mname, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    945\u001b[0m \u001b[39mif\u001b[39;00m read_value:\n\u001b[0;32m    946\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lazy_read(assign_op)\n",
                        "File \u001b[1;32mc:\\Users\\mrpal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py:144\u001b[0m, in \u001b[0;36massign_variable_op\u001b[1;34m(resource, value, validate_shape, name)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[0;32m    143\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[0;32m    145\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mAssignVariableOp\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, resource, value, \u001b[39m\"\u001b[39;49m\u001b[39mvalidate_shape\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    146\u001b[0m       validate_shape)\n\u001b[0;32m    147\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m    148\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
                        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
                    ]
                }
            ],
            "source": [
                "label = []\n",
                "\n",
                "for i in range(len(image_names[:10])):\n",
                "    get_prediction_resnet('asos/only/' + image_names[i])\n",
                "    label.append(get_prediction_resnet('asos/only/' + image_names[i])[0])\n",
                "    \n",
                "    "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "df = pd.DataFrame(label)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>0</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>sunglasses</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>sunglass</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>sunglasses</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>jean</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>trench_coat</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>5</th>\n",
                            "      <td>gown</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>6</th>\n",
                            "      <td>abaya</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>7</th>\n",
                            "      <td>abaya</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>8</th>\n",
                            "      <td>bath_towel</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>9</th>\n",
                            "      <td>lab_coat</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "             0\n",
                            "0   sunglasses\n",
                            "1     sunglass\n",
                            "2   sunglasses\n",
                            "3         jean\n",
                            "4  trench_coat\n",
                            "5         gown\n",
                            "6        abaya\n",
                            "7        abaya\n",
                            "8   bath_towel\n",
                            "9     lab_coat"
                        ]
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# visualize the images\n",
                "import matplotlib.pyplot as plt\n",
                "import matplotlib.image as mpimg\n",
                "import seaborn as sns\n",
                "\n",
                "for i in range(10):\n",
                "    img = mpimg.imread('asos/only/' + image_names[i])\n",
                "    imgplot = plt.imshow(img)\n",
                "    plt.show()\n",
                "    print(df[0][i])"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## here we drop outliers or misclasifications and define our unique types"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "['Backpacks',\n",
                            " 'Belts',\n",
                            " 'Bra',\n",
                            " 'Caps-hats',\n",
                            " 'CasualShoes',\n",
                            " 'Dresses',\n",
                            " 'Earrings',\n",
                            " 'Handbags',\n",
                            " 'Heels',\n",
                            " 'Leggings',\n",
                            " 'Outwear',\n",
                            " 'pijamas',\n",
                            " 'Ring',\n",
                            " 'Sandals',\n",
                            " 'Scarves',\n",
                            " 'Shirts',\n",
                            " 'Shorts',\n",
                            " 'Skirts',\n",
                            " 'Sportswear',\n",
                            " 'Sunglasses',\n",
                            " 'Sweatshirts',\n",
                            " 'Tops',\n",
                            " 'Trousers',\n",
                            " 'Tshirts']"
                        ]
                    },
                    "execution_count": 14,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# read the folder names from the C:\\Users\\mrpal\\OneDrive\\Desktop\\WBS\\fascam\\clothing-dataset-small\\train save them to a list\n",
                "unique_types = [\n",
                "    folder for folder in os.listdir(r'C:\\Users\\mrpal\\OneDrive\\Desktop\\fashcam-final\\finalDataset')]\n",
                "\n",
                "\n",
                "unique_types\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "SNIPPET TO REMOVE EVERY PHOTO FROM THE FOLDERPATH TO THE OTHER FOLDERS THAT BELONG"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "#import shutil\n",
                "#folderpath= r'C:\\Users\\mrpal\\OneDrive\\Desktop\\WBS\\machineLearning\\supervised\\deeplearning\\Imagesfromfashiondataset\\only' \n",
                "# # for each row in the dataframe\n",
                "# for index, row in selected_styles.iterrows():\n",
                "#     # get the image name\n",
                "#     image_name = row['image_name']\n",
                "#     # get the type of clothing\n",
                "#     type = row['articleType']\n",
                "#     # get the source path to the image\n",
                "#     src = os.path.join(r\"folderpath\", image_name).replace(\"\\\\\", \"/\")\n",
                "  \n",
                "#     # get the destination path to the image\n",
                "#     dst = r'Imagesfromfashiondataset/'+os.path.join(type, image_name).replace(\"\\\\\", \"/\")\n",
                "#     # move the image from the source to the destination\n",
                "#     # print(src, dst)\n",
                "#     shutil.move(src, dst)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Backpacks 200\n",
                        "Belts 611\n",
                        "Bra 477\n",
                        "Caps-hats 180\n",
                        "CasualShoes 572\n",
                        "Dresses 659\n",
                        "Earrings 337\n",
                        "Handbags 94\n",
                        "Heels 43\n",
                        "Leggings 177\n",
                        "Outwear 299\n",
                        "pijamas 141\n",
                        "Ring 118\n",
                        "Sandals 361\n",
                        "Scarves 119\n",
                        "Shirts 459\n",
                        "Shorts 327\n",
                        "Skirts 152\n",
                        "Sportswear 304\n",
                        "Sunglasses 1073\n",
                        "Sweatshirts 582\n",
                        "Tops 257\n",
                        "Trousers 896\n",
                        "Tshirts 3072\n"
                    ]
                }
            ],
            "source": [
                "# give the number of files in the folder with the given path\n",
                "def get_number_of_files(path):\n",
                "    return len([f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))])\n",
                "for i in range(len(unique_types)):\n",
                "    print(unique_types[i], get_number_of_files(r'C:\\Users\\mrpal\\OneDrive\\Desktop\\fashcam-final\\finalDataset' + '/' + unique_types[i]))    "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Found 11510 files belonging to 24 classes.\n",
                        "Using 6906 files for training.\n",
                        "Using 4604 files for validation.\n"
                    ]
                }
            ],
            "source": [
                "\n",
                "train_ds, test_ds = tf.keras.utils.image_dataset_from_directory(\n",
                "    r\"C:\\Users\\mrpal\\OneDrive\\Desktop\\fashcam-final\\finalDataset\",\n",
                "    labels=\"inferred\",\n",
                "    validation_split=0.4,\n",
                "    shuffle=True,\n",
                "    subset=\"both\",\n",
                "    seed=1337,\n",
                "    batch_size=32,\n",
                "    image_size=(224, 224),\n",
                "    label_mode='categorical',\n",
                "    color_mode='rgb',\n",
                "    \n",
                "            )\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 52,
            "metadata": {},
            "outputs": [],
            "source": [
                "# data = tf.keras.utils.image_dataset_from_directory(\n",
                "\n",
                "#     r\"C:\\Users\\mrpal\\OneDrive\\Desktop\\fashcam-final\\finalDataset\",\n",
                "#     labels=\"inferred\",\n",
                "#     label_mode='categorical',\n",
                "#     class_names=None,\n",
                "#     color_mode=\"rgb\",\n",
                "#     batch_size=32,\n",
                "#     image_size=(224, 224),\n",
                "#     shuffle=True,\n",
                "#     seed=1337,\n",
                "#     validation_split=0.4,\n",
                "#     subset=\"both\",\n",
                "#     interpolation=\"bilinear\",\n",
                "#     follow_links=False,\n",
                "#     crop_to_aspect_ratio=False,\n",
                "# )\n",
                "# split the data into train and test\n",
                "# train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
                "#     r\"C:\\Users\\mrpal\\OneDrive\\Desktop\\fashcam-final\\finalDataset\",\n",
                "#     validation_split=0.2,\n",
                "#     subset=\"training\",\n",
                "#     seed=1337,\n",
                "#     label_mode='categorical',\n",
                "#     class_names=None,\n",
                "#     color_mode=\"rgb\",\n",
                "#     batch_size=32,\n",
                "#     image_size=(224, 224),\n",
                "#     image_size=image_size,\n",
                "# )\n",
                "# val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
                "#     r\"C:\\Users\\mrpal\\OneDrive\\Desktop\\fashcam-final\\finalDataset\",\n",
                "#     validation_split=0.2,\n",
                "#     subset=\"validation\",\n",
                "#     seed=1337,\n",
                "#     label_mode='categorical',\n",
                "#     class_names=None,\n",
                "#     color_mode=\"rgb\",\n",
                "#     batch_size=32,\n",
                "#     image_size=(224, 224),\n",
                "# )\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [],
            "source": [
                "# import output \n",
                "def train_model_tuning():\n",
                "    # Load the pre-trained ResNet50 model, with the top layer removed\n",
                "    resnet50_model = ResNet50(\n",
                "        weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
                "    #model with 1 layer\n",
                "    cnn_model = resnet50_model.output\n",
                "    cnn_model = Flatten()(cnn_model)\n",
                "    cnn_model = Dense(len(unique_types), activation='softmax')(cnn_model)\n",
                "    # for the 1117 classes\n",
                "    # cnn_model = Dense(len(unique_types), activation='softmax')(cnn_model)\n",
                "    final_model = Model(inputs=resnet50_model.input, outputs=cnn_model)\n",
                "\n",
                "    # Freeze all layers in the base model (except for the top layer)\n",
                "    for layer in resnet50_model.layers:\n",
                "        layer.trainable = False\n",
                "    # Compile the model\n",
                "    final_model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
                "              metrics=['accuracy'])\n",
                "\n",
                "    # Convert the target labels into one-hot encoded format\n",
                "    checkpoint_filepath = r'C:\\Users\\mrpal\\OneDrive\\Desktop\\fashcam-final'\n",
                "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
                "    filepath=checkpoint_filepath,\n",
                "    save_weights_only=False,\n",
                "    monitor='val_accuracy',\n",
                "    mode='max',\n",
                "    save_best_only=True)\n",
                "    \n",
                "    # Train the model\n",
                "    \n",
                "    history = final_model.fit(\n",
                "        train_ds,\n",
                "        batch_size=100, \n",
                "        epochs=12, \n",
                "        verbose=1,\n",
                "        callbacks=[model_checkpoint_callback],\n",
                "        )\n",
                "  \n",
                "    # save the model\n",
                "    final_model.save(\"final_model_v3.h5\")\n",
                "    # serialize model to JSON\n",
                "    # model_json = final_model.to_json()\n",
                "    # with open(\"final_model.json\", \"w\") as json_file:\n",
                "    #     json_file.write(model_json)\n",
                "    # # serialize weights to HDF5\n",
                "    # final_model.save_weights(\"final_model.h5\")\n",
                "    print(\"Saved model to disk\")\n",
                "    \n",
                "    return 0"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1/12\n",
                        "216/216 [==============================] - ETA: 0s - loss: 6.7900 - accuracy: 0.8032WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
                        "216/216 [==============================] - 1878s 9s/step - loss: 6.7900 - accuracy: 0.8032\n",
                        "Epoch 2/12\n",
                        "216/216 [==============================] - ETA: 0s - loss: 1.7161 - accuracy: 0.9399WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
                        "216/216 [==============================] - 1543s 7s/step - loss: 1.7161 - accuracy: 0.9399\n",
                        "Epoch 3/12\n",
                        "216/216 [==============================] - ETA: 0s - loss: 0.6940 - accuracy: 0.9716WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
                        "216/216 [==============================] - 1550s 7s/step - loss: 0.6940 - accuracy: 0.9716\n",
                        "Epoch 4/12\n",
                        "216/216 [==============================] - ETA: 0s - loss: 0.9123 - accuracy: 0.9676WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
                        "216/216 [==============================] - 1548s 7s/step - loss: 0.9123 - accuracy: 0.9676\n",
                        "Epoch 5/12\n",
                        "216/216 [==============================] - ETA: 0s - loss: 0.6748 - accuracy: 0.9790WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
                        "216/216 [==============================] - 1544s 7s/step - loss: 0.6748 - accuracy: 0.9790\n",
                        "Epoch 6/12\n",
                        "216/216 [==============================] - ETA: 0s - loss: 0.4091 - accuracy: 0.9848WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
                        "216/216 [==============================] - 1542s 7s/step - loss: 0.4091 - accuracy: 0.9848\n",
                        "Epoch 7/12\n",
                        "216/216 [==============================] - ETA: 0s - loss: 0.5694 - accuracy: 0.9810WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
                        "216/216 [==============================] - 1550s 7s/step - loss: 0.5694 - accuracy: 0.9810\n",
                        "Epoch 8/12\n",
                        "216/216 [==============================] - ETA: 0s - loss: 0.6066 - accuracy: 0.9829WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
                        "216/216 [==============================] - 1545s 7s/step - loss: 0.6066 - accuracy: 0.9829\n",
                        "Epoch 9/12\n",
                        "216/216 [==============================] - ETA: 0s - loss: 0.4695 - accuracy: 0.9855WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
                        "216/216 [==============================] - 1547s 7s/step - loss: 0.4695 - accuracy: 0.9855\n",
                        "Epoch 10/12\n",
                        "216/216 [==============================] - ETA: 0s - loss: 0.7287 - accuracy: 0.9810WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
                        "216/216 [==============================] - 1552s 7s/step - loss: 0.7287 - accuracy: 0.9810\n",
                        "Epoch 11/12\n",
                        "216/216 [==============================] - ETA: 0s - loss: 0.4955 - accuracy: 0.9880WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
                        "216/216 [==============================] - 1544s 7s/step - loss: 0.4955 - accuracy: 0.9880\n",
                        "Epoch 12/12\n",
                        "216/216 [==============================] - ETA: 0s - loss: 0.3053 - accuracy: 0.9902WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
                        "216/216 [==============================] - 1550s 7s/step - loss: 0.3053 - accuracy: 0.9902\n",
                        "Saved model to disk\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "0"
                        ]
                    },
                    "execution_count": 21,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "train_model_tuning()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "accuracy: 89.68%\n"
                    ]
                }
            ],
            "source": [
                "# import load model\n",
                "from keras.models import load_model\n",
                "\n",
                "loaded_model = load_model('final_model_v3.h5')\n",
                "\n",
                "# evaluate loaded model on test data\n",
                "loaded_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])       \n",
                "score = loaded_model.evaluate(test_ds, verbose=0)\n",
                "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100)) "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "ename": "NameError",
                    "evalue": "name 'loaded_model' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "Cell \u001b[1;32mIn [1], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m   \n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m \n\u001b[1;32m----> 6\u001b[0m y_pred \u001b[39m=\u001b[39m loaded_model\u001b[39m.\u001b[39mpredict(test_ds)\n\u001b[0;32m      7\u001b[0m y_pred \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(y_pred, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m      8\u001b[0m y_true \u001b[39m=\u001b[39m test_ds\u001b[39m.\u001b[39mclasses\n",
                        "\u001b[1;31mNameError\u001b[0m: name 'loaded_model' is not defined"
                    ]
                }
            ],
            "source": [
                "# confusion matrix\n",
                "from sklearn.metrics import confusion_matrix\n",
                "import seaborn as sns   \n",
                "import matplotlib.pyplot as plt \n",
                "loaded_model.compile(\n",
                "    optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
                "\n",
                "y_pred = loaded_model.predict(test_ds)\n",
                "y_pred = np.argmax(y_pred, axis=1)\n",
                "y_true = test_ds.classes\n",
                "cm = confusion_matrix(y_true, y_pred)\n",
                "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
                "plt.figure(figsize=(10,10))\n",
                "sns.heatmap(cm, annot=True, fmt='.2f', xticklabels=unique_types, yticklabels=unique_types)\n",
                "plt.ylabel('True label')\n",
                "plt.xlabel('Predicted label')\n",
                "plt.show()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### function that uses fine tunin with resnet50 to predict the class and the sparse matrix of image given"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_prediction_tuning(img_path):\n",
                "    # load json and create model\n",
                "    json_file = open('final_model.json', 'r')\n",
                "    loaded_model_json = json_file.read()\n",
                "    json_file.close()\n",
                "    loaded_model = model_from_json(loaded_model_json)\n",
                "    # load weights into new model\n",
                "    loaded_model.load_weights(\"final_model.h5\")\n",
                "    # Load an image to use for prediction\n",
                "    img = load_img(img_path, target_size=(224, 224,3))\n",
                "    x = img_to_array(img)\n",
                "    x = np.expand_dims(x, axis=0)\n",
                "    x = preprocess_input(x)\n",
                "    # result = loaded_model.predict(x)\n",
                "    # evaluate loaded model on test data\n",
                "    loaded_model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
                "                         metrics=['accuracy'])\n",
                "    result = loaded_model.predict(x)\n",
                "    # get the percentage of the prediction\n",
                "    \n",
                "    \n",
                "    return (result,unique_types[np.argmax(result)])\n",
                "    \n",
                "    \n",
                "    \n",
                "  \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "ename": "NameError",
                    "evalue": "name 'test_x' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "Cell \u001b[1;32mIn [21], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m Y_pred \u001b[39m=\u001b[39m loaded_model\u001b[39m.\u001b[39mpredict(test_x[:\u001b[39m50\u001b[39m])\n\u001b[0;32m      7\u001b[0m y_pred \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(test_y, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m      8\u001b[0m y_true \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(test_y[:\u001b[39m50\u001b[39m], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
                        "\u001b[1;31mNameError\u001b[0m: name 'test_x' is not defined"
                    ]
                }
            ],
            "source": [
                "# # confusion matrix\n",
                "#import seaborn as sns\n",
                "from sklearn.metrics import confusion_matrix\n",
                "import seaborn as sns\n",
                "import matplotlib.pyplot as plt\n",
                "Y_pred = loaded_model.predict(test_x[:50])\n",
                "y_pred = np.argmax(test_y, axis=1)\n",
                "y_true = np.argmax(test_y[:50], axis=1)\n",
                "confusion_matrix(y_true, y_pred)\n",
                "cm = confusion_matrix(y_true, y_pred)   \n",
                "plt.figure(figsize=(20,20))\n",
                "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
                "plt.title(\"Confusion matrix\")\n",
                "plt.ylabel('True label')\n",
                "plt.xlabel('Predicted label')\n",
                "plt.show()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### function that uses vgg16 model to predict the class and the sparse matrix of image given"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "VGG-19 is an improved version of vgg16 and it is 19 layers deep.  a pretrained version of the network trained on more than a million images from the ImageNet database. The pretrained network can classify images into 1000 object categories, such as keyboard, mouse, pencil, and many animals"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_prediction_vgg16(img_path):\n",
                "    # imgs_model_width, imgs_model_height = 224, 224\n",
                "    # load the model\n",
                "    vgg_model = vgg16.VGG16(weights='imagenet')\n",
                "\n",
                "    original = load_img(img_path, target_size=(224, 224))\n",
                "    numpy_image = img_to_array(original)\n",
                "    image_batch = np.expand_dims(numpy_image, axis=0)\n",
                "    images = np.vstack([image_batch])\n",
                "\n",
                "    processed_img = preprocess_input(images.copy())\n",
                "    prediction = classifier.predict(images)\n",
                "    result = feat_extractor.predict(images)\n",
                "    # help the model to predict the class\n",
                "    return result, vgg16.decode_predictions(prediction, top=1)[0][0][1]\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# # load the model\n",
                "# vgg_model = vgg16.VGG16(weights='imagenet')\n",
                "\n",
                "# # remove the last layers in order to get features instead of predictions\n",
                "\n",
                "# feat_extractor = Model(inputs=vgg_model.input,\n",
                "#                        outputs=vgg_model.get_layer(\"fc2\").output)\n",
                "# # get the model with the last layer in order to get predictions\n",
                "# classifier = Model(inputs=vgg_model.input,\n",
                "#                      outputs=vgg_model.get_layer(\"predictions\").output)\n",
                "\n",
                "# # print the layers of the CNN\n",
                "# feat_extractor.summary()\n",
                "# classifier.summary()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### testing all models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "1/1 [==============================] - 0s 82ms/step\n"
                    ]
                },
                {
                    "ename": "",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31mCanceled future for execute_request message before replies were done"
                    ]
                }
            ],
            "source": [
                "test_file = r\"C:\\Users\\mrpal\\OneDrive\\Desktop\\WBS\\machineLearning\\supervised\\deeplearning\\image3.jpg\"\n",
                "\n",
                "get_prediction_vgg16(test_file)[1]\n",
                "get_prediction_resnet(test_file)[1]\n",
                "get_prediction_tuning(test_file)[1]\n",
                "# give a black frame to the picture through load image and then show it:\n",
                "original = load_img(test_file)\n",
                "plt.imshow(original)\n",
                "print(\"vgg16 says \" + get_prediction_vgg16(test_file)[1])\n",
                "print(\"resnet says \" + get_prediction_resnet(test_file)[1])\n",
                "print (\"tuned model says \" + get_prediction_tuning(test_file)[1])\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# feat_extractor.predict(preprocess_input(np.expand_dims(load_img(r'C:\\Users\\mrpal\\OneDrive\\Desktop\\WBS\\machineLearning\\supervised\\deeplearning\\FasCam\\clothing-dataset-small\\dress\\009b3c31-fb62-45c0-be9a-37a5c238cb88.jpg', target_size=(imgs_model_width, imgs_model_height)), axis=0)))"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### function that gets a list of images and returns the features of those images"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# function that gets a list of images and returns the features of those images\n",
                "def get_features(img_paths, category_folder_name):\n",
                "    imgs_model_width, imgs_model_height = 224, 224\n",
                "    nb_closest_images = 5\n",
                "    importedImages = []\n",
                "    for f in img_paths:\n",
                "        filename = f\n",
                "        original = load_img(filename, target_size=(224, 224))\n",
                "        numpy_image = img_to_array(original)\n",
                "        image_batch = np.expand_dims(numpy_image, axis=0)\n",
                "\n",
                "        importedImages.append(image_batch)\n",
                "    images = np.vstack(importedImages)\n",
                "    processed_imgs = preprocess_input(images.copy())\n",
                "    # load the model\n",
                "    vgg_model = vgg16.VGG16(weights='imagenet')\n",
                "    # remove the last layers in order to get features instead of predictions\n",
                "    feat_extractor = Model(inputs=vgg_model.input,\n",
                "                           outputs=vgg_model.get_layer(\"fc2\").output)\n",
                "    # print the layers of the CNN\n",
                "    feat_extractor.summary()\n",
                "    imgs_features = feat_extractor.predict(processed_imgs)\n",
                "    print(\"features successfully extracted!\")\n",
                "    # save it as csv file\n",
                "    np.savetxt(f'{category_folder_name}.csv', imgs_features, delimiter=\",\")\n",
                "    return imgs_features"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "get_features(list_directory[:5000], 'imagesfromfashiondata')\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### function that takes an image as input and applies the cosine similarity with the features from csv to get the closest images\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "# function that takes an image as input and applies the cosine similarity with the features from csv to get the closest images\n",
                "def get_closest_images(img_path, nb_closest_images=4):\n",
                "    # prediction about the class of the image\n",
                "    available_class = get_prediction_tuning(img_path)\n",
                "    available_class = \"Outwear\"\n",
                "    # load the features from csv\n",
                "\n",
                "    features = np.genfromtxt('Outwear.csv', delimiter=',')\n",
                "    # get the features of the image\n",
                "\n",
                "    model = ResNet50(weights='imagenet', include_top=True)\n",
                "    feat_extractor = Model(\n",
                "        inputs=model.input, outputs=model.get_layer(\"avg_pool\").output)\n",
                "    feat_extractor.summary()\n",
                "\n",
                "    img_features = feat_extractor.predict(preprocess_input(\n",
                "        np.expand_dims(load_img(img_path, target_size=(224, 224)), axis=0)))\n",
                "    # get the cosine similarity\n",
                "    cosSimilarities = cosine_similarity(img_features, features)\n",
                "\n",
                "    print(\"-----------------------------------------------------------------------\")\n",
                "    print(\"original product:\")\n",
                "    original = load_img(img_path, target_size=(\n",
                "        224, 224))\n",
                "    plt.imshow(original)\n",
                "    plt.show()\n",
                "    print(\"-----------------------------------------------------------------------\")\n",
                "    print(\"most similar products:\")\n",
                "    # get the indexes of the closest images\n",
                "    closest_imgs_indexes = cosSimilarities.argsort()[0][-nb_closest_images:]\n",
                "    # similarity score of the closest images\n",
                "    closest_imgs_similarities = cosSimilarities[0][closest_imgs_indexes]\n",
                "\n",
                "    # get the closest images\n",
                "    closest_imgs = [shopfiles[i]\n",
                "                    for i in closest_imgs_indexes if i < len(shopfiles)]\n",
                "    for i in range(0, nb_closest_images):\n",
                "\n",
                "        original = load_img(closest_imgs[i], target_size=(\n",
                "            224, 224))\n",
                "        plt.imshow(original)\n",
                "        plt.show()\n",
                "        print(\"similarity score:\", closest_imgs_similarities[i])\n",
                "    return 0\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.4"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "e5d44d20471fed6b31c84e96a507e39677b7979bf00486c2e6552218c91082f0"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
