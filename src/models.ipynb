{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Final Model \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TensorFlow and tf.keras\n",
                "import tensorflow as tf\n",
                "# recommended models\n",
                "from tensorflow.keras.applications.resnet50 import ResNet50\n",
                "\n",
                "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
                "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
                "from tensorflow.keras.applications.inception_resnet_v2 import preprocess_input, decode_predictions\n",
                "from keras.applications.vgg19 import VGG19\n",
                "# keras\n",
                "\n",
                "from keras.applications import vgg16\n",
                "from keras.applications.vgg19 import VGG19\n",
                "from keras.applications import ResNet50\n",
                "from tensorflow.keras.utils import load_img, img_to_array\n",
                "from keras.applications.imagenet_utils import preprocess_input\n",
                "from sklearn.metrics.pairwise import cosine_similarity\n",
                "from tensorflow.keras.models import model_from_json\n",
                "from sklearn.model_selection import train_test_split\n",
                "from keras.models import Model\n",
                "from keras.layers import Dense, GlobalAveragePooling2D\n",
                "from tensorflow.keras.preprocessing import image\n",
                "#CNN Model\n",
                "from tensorflow.keras.models import Sequential\n",
                "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Flatten, Dense, Dropout\n",
                "from tensorflow.keras.optimizers import Adam\n",
                "from tensorflow.keras.callbacks import ModelCheckpoint\n",
                "\n",
                "# from tensorflow.keras.callbacks import TensorBoard\n",
                "from keras.utils import to_categorical\n",
                "#import resnet50\n",
                "# Helper libraries\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import pandas as pd\n",
                "# get the array with the class names from the folder \n",
                "# read foldernames\n",
                "import os\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "# read all the paths from the folder\n",
                "def get_paths(folder):\n",
                "    paths = []\n",
                "    for root, dirs, files in os.walk(folder):\n",
                "        for file in files:\n",
                "            # if file.endswith(\".jpg\"):\n",
                "            paths.append(os.path.join(root, file))\n",
                "    return paths"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "shop_images = get_paths(\n",
                "    r'C:\\Users\\mrpal\\OneDrive\\Desktop\\fashcam-v3\\asos')\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## function that loads vgg models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "\n",
                "def get_models():\n",
                "  # load the vgg models\n",
                "  vgg16_model = vgg16.VGG16(weights='imagenet')\n",
                "  vgg19_model = VGG19(weights='imagenet', include_top=False)\n",
                "\n",
                "  # remove the last layers in order to get features instead of predictions\n",
                "  feat_extractor_vgg19 = Model(inputs=vgg19_model.input,\n",
                "                               outputs=vgg19_model.get_layer(\"block5_pool\").output)\n",
                "  feat_extractor = Model(inputs=vgg16_model.input,\n",
                "                         outputs=vgg16_model.get_layer(\"fc2\").output)\n",
                "  # get the model with the last layer in order to get predictions\n",
                "  classifier = Model(inputs=vgg16_model.input,\n",
                "                     outputs=vgg16_model.get_layer(\"predictions\").output)\n",
                "  # print the layers of the CNN\n",
                "  feat_extractor.summary()\n",
                "  # feat_extractor_vgg19.summary()\n",
                "  classifier.summary()\n",
                "  return feat_extractor, classifier, feat_extractor_vgg19\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "feat_extractor = get_models()[0]\n",
                "classifier = get_models()[1]\n",
                "feat_extractor_vgg19 = get_models()[2]\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "### function that uses inceptionresnet to predict the class and the sparse matrix of image given"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_prediction_InceptionResNetV2(img_path):\n",
                "\n",
                "    # load\n",
                "    model = InceptionResNetV2(weights='imagenet', include_top=True)\n",
                "    img = load_img(img_path, target_size=(299, 299))\n",
                "    x = img_to_array(img)\n",
                "    x = np.expand_dims(x, axis=0)\n",
                "    x = preprocess_input(x)\n",
                "    # get prediction\n",
                "    features = model.predict(x)\n",
                "    predictions = decode_predictions(features, top=2)\n",
                "    propability = predictions[0][0][2]\n",
                "\n",
                "    return predictions[0][0] if propability > 0.5 else (0, f'{propability} too low')\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### function that uses resnet to predict the class and the sparse matrix of image given"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                " ResNet-50 is 50 layers deep and is trained on a million images of 1000 categories from the ImageNet database.\n",
                " the model has over 23 million trainable parameters"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_prediction_resnet(img_path):\n",
                "\n",
                "    # Load the pre-trained ResNet50 model, with the top layer removed\n",
                "    model = ResNet50(weights='imagenet', include_top=True)\n",
                "\n",
                "    # Load an image to use for prediction\n",
                "    img = load_img(img_path, target_size=(224, 224))\n",
                "    x = img_to_array(img)\n",
                "    x = np.expand_dims(x, axis=0)\n",
                "    x = preprocess_input(x)\n",
                "\n",
                "    # Get the predictions from the model\n",
                "    features = model.predict(x)\n",
                "\n",
                "    # Print the top 5 predictions\n",
                "    predictions = decode_predictions(features, top=2)\n",
                "    # for p in predictions[0]:\n",
                "    #     print(f\"Class: {p[1]}, Probability: {p[2]:.2f}\")\n",
                "    propability = predictions[0][0][2]\n",
                "    return predictions[0][0] if propability > 0.5 else (0, f'{propability} too low')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {},
            "outputs": [],
            "source": [
                "image_names = os.listdir(r'C:\\Users\\mrpal\\OneDrive\\Desktop\\fashcam-v3\\asos\\unlabeled')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "1/1 [==============================] - 7s 7s/step\n",
                        "1/1 [==============================] - 6s 6s/step\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "C:\\Users\\mrpal\\AppData\\Local\\Temp\\ipykernel_10840\\2972023894.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
                        "  asos_df = asos_df.append({'image_name': f'image{i}.jpg',\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "1/1 [==============================] - 6s 6s/step\n",
                        "1/1 [==============================] - 6s 6s/step\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "C:\\Users\\mrpal\\AppData\\Local\\Temp\\ipykernel_10840\\2972023894.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
                        "  asos_df = asos_df.append({'image_name': f'image{i}.jpg',\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "1/1 [==============================] - 6s 6s/step\n",
                        "1/1 [==============================] - 6s 6s/step\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "C:\\Users\\mrpal\\AppData\\Local\\Temp\\ipykernel_10840\\2972023894.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
                        "  asos_df = asos_df.append({'image_name': f'image{i}.jpg',\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "1/1 [==============================] - 6s 6s/step\n",
                        "1/1 [==============================] - 7s 7s/step\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "C:\\Users\\mrpal\\AppData\\Local\\Temp\\ipykernel_10840\\2972023894.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
                        "  asos_df = asos_df.append({'image_name': f'image{i}.jpg',\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "1/1 [==============================] - 5s 5s/step\n",
                        "1/1 [==============================] - 6s 6s/step\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "C:\\Users\\mrpal\\AppData\\Local\\Temp\\ipykernel_10840\\2972023894.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
                        "  asos_df = asos_df.append({'image_name': f'image{i}.jpg',\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "1/1 [==============================] - 5s 5s/step\n",
                        "1/1 [==============================] - 5s 5s/step\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "C:\\Users\\mrpal\\AppData\\Local\\Temp\\ipykernel_10840\\2972023894.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
                        "  asos_df = asos_df.append({'image_name': f'image{i}.jpg',\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "1/1 [==============================] - 5s 5s/step\n",
                        "1/1 [==============================] - 5s 5s/step\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "C:\\Users\\mrpal\\AppData\\Local\\Temp\\ipykernel_10840\\2972023894.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
                        "  asos_df = asos_df.append({'image_name': f'image{i}.jpg',\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "1/1 [==============================] - 5s 5s/step\n",
                        "1/1 [==============================] - 5s 5s/step\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "C:\\Users\\mrpal\\AppData\\Local\\Temp\\ipykernel_10840\\2972023894.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
                        "  asos_df = asos_df.append({'image_name': f'image{i}.jpg',\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "1/1 [==============================] - 5s 5s/step\n",
                        "1/1 [==============================] - 6s 6s/step\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "C:\\Users\\mrpal\\AppData\\Local\\Temp\\ipykernel_10840\\2972023894.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
                        "  asos_df = asos_df.append({'image_name': f'image{i}.jpg',\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "1/1 [==============================] - 6s 6s/step\n",
                        "1/1 [==============================] - 6s 6s/step\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "C:\\Users\\mrpal\\AppData\\Local\\Temp\\ipykernel_10840\\2972023894.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
                        "  asos_df = asos_df.append({'image_name': f'image{i}.jpg',\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>image_name</th>\n",
                            "      <th>prediction</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>image0.jpg</td>\n",
                            "      <td>comic_book</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>image1.jpg</td>\n",
                            "      <td>comic_book</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>image2.jpg</td>\n",
                            "      <td>comic_book</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>image3.jpg</td>\n",
                            "      <td>comic_book</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>image4.jpg</td>\n",
                            "      <td>comic_book</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>5</th>\n",
                            "      <td>image5.jpg</td>\n",
                            "      <td>comic_book</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>6</th>\n",
                            "      <td>image6.jpg</td>\n",
                            "      <td>comic_book</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>7</th>\n",
                            "      <td>image7.jpg</td>\n",
                            "      <td>comic_book</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>8</th>\n",
                            "      <td>image8.jpg</td>\n",
                            "      <td>comic_book</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>9</th>\n",
                            "      <td>image9.jpg</td>\n",
                            "      <td>comic_book</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "   image_name  prediction\n",
                            "0  image0.jpg  comic_book\n",
                            "1  image1.jpg  comic_book\n",
                            "2  image2.jpg  comic_book\n",
                            "3  image3.jpg  comic_book\n",
                            "4  image4.jpg  comic_book\n",
                            "5  image5.jpg  comic_book\n",
                            "6  image6.jpg  comic_book\n",
                            "7  image7.jpg  comic_book\n",
                            "8  image8.jpg  comic_book\n",
                            "9  image9.jpg  comic_book"
                        ]
                    },
                    "execution_count": 29,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "asos_df = pd.DataFrame(columns=['image_name', 'prediction'])\n",
                "for i in range(0, 10):\n",
                " \n",
                "    asos_df = asos_df.append({'image_name': f'image{i}.jpg',\n",
                "                              'prediction': get_prediction_InceptionResNetV2(\n",
                "                                  f'C:/Users/mrpal/OneDrive/Desktop/fashcam-v3/asos/unlabeled/image{i}.jpg')[1]},\n",
                "\n",
                "                             ignore_index=True)\n",
                "\n",
                "asos_df\n",
                "\n",
                "    \n",
                "    "
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## here we drop outliers or misclasifications and define our unique types"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "['bulletproof_vest',\n",
                            " 'cardigan',\n",
                            " 'jersey',\n",
                            " 'sunglass',\n",
                            " 'sweatshirt',\n",
                            " 'swimming_trunks',\n",
                            " 'trench_coat',\n",
                            " 'unlabeled',\n",
                            " 'velvet']"
                        ]
                    },
                    "execution_count": 30,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# read the folder names from the C:\\Users\\mrpal\\OneDrive\\Desktop\\WBS\\fascam\\clothing-dataset-small\\train save them to a list\n",
                "unique_types = [\n",
                "    folder for folder in os.listdir(r'C:\\Users\\mrpal\\OneDrive\\Desktop\\fashcam-v3\\asos')]\n",
                "\n",
                "\n",
                "unique_types\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "SNIPPET TO REMOVE EVERY PHOTO FROM THE FOLDERPATH TO THE OTHER FOLDERS THAT BELONG"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "#import shutil\n",
                "#folderpath= r'C:\\Users\\mrpal\\OneDrive\\Desktop\\WBS\\machineLearning\\supervised\\deeplearning\\Imagesfromfashiondataset\\unlabeled' \n",
                "# # for each row in the dataframe\n",
                "# for index, row in selected_styles.iterrows():\n",
                "#     # get the image name\n",
                "#     image_name = row['image_name']\n",
                "#     # get the type of clothing\n",
                "#     type = row['articleType']\n",
                "#     # get the source path to the image\n",
                "#     src = os.path.join(r\"folderpath\", image_name).replace(\"\\\\\", \"/\")\n",
                "  \n",
                "#     # get the destination path to the image\n",
                "#     dst = r'Imagesfromfashiondataset/'+os.path.join(type, image_name).replace(\"\\\\\", \"/\")\n",
                "#     # move the image from the source to the destination\n",
                "#     # print(src, dst)\n",
                "#     shutil.move(src, dst)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "bulletproof_vest 0\n",
                        "cardigan 0\n",
                        "jersey 0\n",
                        "sunglass 0\n",
                        "sweatshirt 0\n",
                        "swimming_trunks 0\n",
                        "trench_coat 0\n",
                        "unlabeled 13879\n",
                        "velvet 0\n"
                    ]
                }
            ],
            "source": [
                "# give the number of files in the folder with the given path\n",
                "def get_number_of_files(path):\n",
                "    return len([f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))])\n",
                "for i in range(len(unique_types)):\n",
                "    print(unique_types[i], get_number_of_files(r'C:\\Users\\mrpal\\OneDrive\\Desktop\\fashcam-v3\\asos' + '\\\\' + unique_types[i]))    "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Found 11510 files belonging to 24 classes.\n",
                        "Using 6906 files for training.\n",
                        "Using 4604 files for validation.\n"
                    ]
                }
            ],
            "source": [
                "\n",
                "train_ds, test_ds = tf.keras.utils.image_dataset_from_directory(\n",
                "    r\"C:\\Users\\mrpal\\OneDrive\\Desktop\\fashcam-v3\\finalDataset\",\n",
                "    labels=\"inferred\",\n",
                "    validation_split=0.4,\n",
                "    shuffle=True,\n",
                "    subset=\"both\",\n",
                "    seed=1337,\n",
                "    batch_size=32,\n",
                "    image_size=(224, 224),\n",
                "    label_mode='categorical',\n",
                "    color_mode='rgb',\n",
                "    \n",
                "            )\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 52,
            "metadata": {},
            "outputs": [],
            "source": [
                "# data = tf.keras.utils.image_dataset_from_directory(\n",
                "\n",
                "#     r\"C:\\Users\\mrpal\\OneDrive\\Desktop\\fashcam-v3\\finalDataset\",\n",
                "#     labels=\"inferred\",\n",
                "#     label_mode='categorical',\n",
                "#     class_names=None,\n",
                "#     color_mode=\"rgb\",\n",
                "#     batch_size=32,\n",
                "#     image_size=(224, 224),\n",
                "#     shuffle=True,\n",
                "#     seed=1337,\n",
                "#     validation_split=0.4,\n",
                "#     subset=\"both\",\n",
                "#     interpolation=\"bilinear\",\n",
                "#     follow_links=False,\n",
                "#     crop_to_aspect_ratio=False,\n",
                "# )\n",
                "# split the data into train and test\n",
                "# train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
                "#     r\"C:\\Users\\mrpal\\OneDrive\\Desktop\\fashcam-v3\\finalDataset\",\n",
                "#     validation_split=0.2,\n",
                "#     subset=\"training\",\n",
                "#     seed=1337,\n",
                "#     label_mode='categorical',\n",
                "#     class_names=None,\n",
                "#     color_mode=\"rgb\",\n",
                "#     batch_size=32,\n",
                "#     image_size=(224, 224),\n",
                "#     image_size=image_size,\n",
                "# )\n",
                "# val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
                "#     r\"C:\\Users\\mrpal\\OneDrive\\Desktop\\fashcam-v3\\finalDataset\",\n",
                "#     validation_split=0.2,\n",
                "#     subset=\"validation\",\n",
                "#     seed=1337,\n",
                "#     label_mode='categorical',\n",
                "#     class_names=None,\n",
                "#     color_mode=\"rgb\",\n",
                "#     batch_size=32,\n",
                "#     image_size=(224, 224),\n",
                "# )\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [],
            "source": [
                "# import output \n",
                "def train_model_tuning():\n",
                "    # Load the pre-trained ResNet50 model, with the top layer removed\n",
                "    resnet50_model = ResNet50(\n",
                "        weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
                "    #model with 1 layer\n",
                "    cnn_model = resnet50_model.output\n",
                "    cnn_model = Flatten()(cnn_model)\n",
                "    cnn_model = Dense(len(unique_types), activation='softmax')(cnn_model)\n",
                "    # for the 1117 classes\n",
                "    # cnn_model = Dense(len(unique_types), activation='softmax')(cnn_model)\n",
                "    final_model = Model(inputs=resnet50_model.input, outputs=cnn_model)\n",
                "\n",
                "    # Freeze all layers in the base model (except for the top layer)\n",
                "    for layer in resnet50_model.layers:\n",
                "        layer.trainable = False\n",
                "    # Compile the model\n",
                "    final_model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
                "              metrics=['accuracy'])\n",
                "\n",
                "    # Convert the target labels into one-hot encoded format\n",
                "    checkpoint_filepath = r'C:\\Users\\mrpal\\OneDrive\\Desktop\\fashcam-v3'\n",
                "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
                "    filepath=checkpoint_filepath,\n",
                "    save_weights_only=False,\n",
                "    monitor='val_accuracy',\n",
                "    mode='max',\n",
                "    save_best_only=True)\n",
                "    \n",
                "    # Train the model\n",
                "    \n",
                "    history = final_model.fit(\n",
                "        train_ds,\n",
                "        batch_size=100, \n",
                "        epochs=12, \n",
                "        verbose=1,\n",
                "        callbacks=[model_checkpoint_callback],\n",
                "        )\n",
                "  \n",
                "    # save the model\n",
                "    final_model.save(\"final_model_v3.h5\")\n",
                "    # serialize model to JSON\n",
                "    # model_json = final_model.to_json()\n",
                "    # with open(\"final_model.json\", \"w\") as json_file:\n",
                "    #     json_file.write(model_json)\n",
                "    # # serialize weights to HDF5\n",
                "    # final_model.save_weights(\"final_model.h5\")\n",
                "    print(\"Saved model to disk\")\n",
                "    \n",
                "    return 0"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_model_tuning()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "accuracy: 89.68%\n"
                    ]
                }
            ],
            "source": [
                "# import load model\n",
                "from keras.models import load_model\n",
                "\n",
                "loaded_model = load_model('final_model_v3.h5')\n",
                "\n",
                "# evaluate loaded model on test data\n",
                "loaded_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])       \n",
                "score = loaded_model.evaluate(test_ds, verbose=0)\n",
                "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100)) "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# confusion matrix\n",
                "from sklearn.metrics import confusion_matrix\n",
                "import seaborn as sns   \n",
                "import matplotlib.pyplot as plt \n",
                "loaded_model.compile(\n",
                "    optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
                "\n",
                "y_pred = loaded_model.predict(test_ds)\n",
                "y_pred = np.argmax(y_pred, axis=1)\n",
                "y_true = test_ds.classes\n",
                "cm = confusion_matrix(y_true, y_pred)\n",
                "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
                "plt.figure(figsize=(10,10))\n",
                "sns.heatmap(cm, annot=True, fmt='.2f', xticklabels=unique_types, yticklabels=unique_types)\n",
                "plt.ylabel('True label')\n",
                "plt.xlabel('Predicted label')\n",
                "plt.show()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### function that uses fine tunin with resnet50 to predict the class and the sparse matrix of image given"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_prediction_tuning(img_path):\n",
                "    # load json and create model\n",
                "    json_file = open('final_model.json', 'r')\n",
                "    loaded_model_json = json_file.read()\n",
                "    json_file.close()\n",
                "    loaded_model = model_from_json(loaded_model_json)\n",
                "    # load weights into new model\n",
                "    loaded_model.load_weights(\"final_model.h5\")\n",
                "    # Load an image to use for prediction\n",
                "    img = load_img(img_path, target_size=(224, 224,3))\n",
                "    x = img_to_array(img)\n",
                "    x = np.expand_dims(x, axis=0)\n",
                "    x = preprocess_input(x)\n",
                "    # result = loaded_model.predict(x)\n",
                "    # evaluate loaded model on test data\n",
                "    loaded_model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
                "                         metrics=['accuracy'])\n",
                "    result = loaded_model.predict(x)\n",
                "    # get the percentage of the prediction\n",
                "    \n",
                "    \n",
                "    return (result,unique_types[np.argmax(result)])\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "ename": "NameError",
                    "evalue": "name 'test_x' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "Cell \u001b[1;32mIn [21], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m Y_pred \u001b[39m=\u001b[39m loaded_model\u001b[39m.\u001b[39mpredict(test_x[:\u001b[39m50\u001b[39m])\n\u001b[0;32m      7\u001b[0m y_pred \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(test_y, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m      8\u001b[0m y_true \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(test_y[:\u001b[39m50\u001b[39m], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
                        "\u001b[1;31mNameError\u001b[0m: name 'test_x' is not defined"
                    ]
                }
            ],
            "source": [
                "# # confusion matrix\n",
                "#import seaborn as sns\n",
                "from sklearn.metrics import confusion_matrix\n",
                "import seaborn as sns\n",
                "import matplotlib.pyplot as plt\n",
                "Y_pred = loaded_model.predict(test_x[:50])\n",
                "y_pred = np.argmax(test_y, axis=1)\n",
                "y_true = np.argmax(test_y[:50], axis=1)\n",
                "confusion_matrix(y_true, y_pred)\n",
                "cm = confusion_matrix(y_true, y_pred)   \n",
                "plt.figure(figsize=(20,20))\n",
                "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
                "plt.title(\"Confusion matrix\")\n",
                "plt.ylabel('True label')\n",
                "plt.xlabel('Predicted label')\n",
                "plt.show()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### function that uses vgg16 model to predict the class and the sparse matrix of image given"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_prediction_vgg16(img_path):\n",
                "    # imgs_model_width, imgs_model_height = 224, 224\n",
                "    # load the model\n",
                "    vgg_model = vgg16.VGG16(weights='imagenet')\n",
                "\n",
                "    original = load_img(img_path, target_size=(224, 224))\n",
                "    numpy_image = img_to_array(original)\n",
                "    image_batch = np.expand_dims(numpy_image, axis=0)\n",
                "    images = np.vstack([image_batch])\n",
                "\n",
                "    processed_img = preprocess_input(images.copy())\n",
                "    prediction = classifier.predict(images)\n",
                "    result = feat_extractor.predict(images)\n",
                "    # help the model to predict the class\n",
                "    return result, vgg16.decode_predictions(prediction, top=1)[0][0][1]\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# # load the model\n",
                "# vgg_model = vgg16.VGG16(weights='imagenet')\n",
                "\n",
                "# # remove the last layers in order to get features instead of predictions\n",
                "\n",
                "# feat_extractor = Model(inputs=vgg_model.input,\n",
                "#                        outputs=vgg_model.get_layer(\"fc2\").output)\n",
                "# # get the model with the last layer in order to get predictions\n",
                "# classifier = Model(inputs=vgg_model.input,\n",
                "#                      outputs=vgg_model.get_layer(\"predictions\").output)\n",
                "\n",
                "# # print the layers of the CNN\n",
                "# feat_extractor.summary()\n",
                "# classifier.summary()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### testing all models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "1/1 [==============================] - 0s 82ms/step\n"
                    ]
                },
                {
                    "ename": "",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31mCanceled future for execute_request message before replies were done"
                    ]
                }
            ],
            "source": [
                "test_file = r\"C:\\Users\\mrpal\\OneDrive\\Desktop\\WBS\\machineLearning\\supervised\\deeplearning\\image3.jpg\"\n",
                "\n",
                "get_prediction_vgg16(test_file)[1]\n",
                "get_prediction_resnet(test_file)[1]\n",
                "get_prediction_tuning(test_file)[1]\n",
                "# give a black frame to the picture through load image and then show it:\n",
                "original = load_img(test_file)\n",
                "plt.imshow(original)\n",
                "print(\"vgg16 says \" + get_prediction_vgg16(test_file)[1])\n",
                "print(\"resnet says \" + get_prediction_resnet(test_file)[1])\n",
                "print (\"tuned model says \" + get_prediction_tuning(test_file)[1])\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# feat_extractor.predict(preprocess_input(np.expand_dims(load_img(r'C:\\Users\\mrpal\\OneDrive\\Desktop\\WBS\\machineLearning\\supervised\\deeplearning\\FasCam\\clothing-dataset-small\\dress\\009b3c31-fb62-45c0-be9a-37a5c238cb88.jpg', target_size=(imgs_model_width, imgs_model_height)), axis=0)))"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### function that gets a list of images and returns the features of those images"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# function that gets a list of images and returns the features of those images\n",
                "def get_features(img_paths, category_folder_name):\n",
                "    imgs_model_width, imgs_model_height = 224, 224\n",
                "    nb_closest_images = 5\n",
                "    importedImages = []\n",
                "    for f in img_paths:\n",
                "        filename = f\n",
                "        original = load_img(filename, target_size=(224, 224))\n",
                "        numpy_image = img_to_array(original)\n",
                "        image_batch = np.expand_dims(numpy_image, axis=0)\n",
                "\n",
                "        importedImages.append(image_batch)\n",
                "    images = np.vstack(importedImages)\n",
                "    processed_imgs = preprocess_input(images.copy())\n",
                "    # load the model\n",
                "    vgg_model = vgg16.VGG16(weights='imagenet')\n",
                "    # remove the last layers in order to get features instead of predictions\n",
                "    feat_extractor = Model(inputs=vgg_model.input,\n",
                "                           outputs=vgg_model.get_layer(\"fc2\").output)\n",
                "    # print the layers of the CNN\n",
                "    feat_extractor.summary()\n",
                "    imgs_features = feat_extractor.predict(processed_imgs)\n",
                "    print(\"features successfully extracted!\")\n",
                "    # save it as csv file\n",
                "    np.savetxt(f'{category_folder_name}.csv', imgs_features, delimiter=\",\")\n",
                "    return imgs_features"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "get_features(list_directory[:5000], 'imagesfromfashiondata')\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### function that takes an image as input and applies the cosine similarity with the features from csv to get the closest images\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "# function that takes an image as input and applies the cosine similarity with the features from csv to get the closest images\n",
                "def get_closest_images(img_path, nb_closest_images=4):\n",
                "    # prediction about the class of the image\n",
                "    available_class = get_prediction_tuning(img_path)\n",
                "    available_class = \"Outwear\"\n",
                "    # load the features from csv\n",
                "\n",
                "    features = np.genfromtxt('Outwear.csv', delimiter=',')\n",
                "    # get the features of the image\n",
                "\n",
                "    model = ResNet50(weights='imagenet', include_top=True)\n",
                "    feat_extractor = Model(\n",
                "        inputs=model.input, outputs=model.get_layer(\"avg_pool\").output)\n",
                "    feat_extractor.summary()\n",
                "\n",
                "    img_features = feat_extractor.predict(preprocess_input(\n",
                "        np.expand_dims(load_img(img_path, target_size=(224, 224)), axis=0)))\n",
                "    # get the cosine similarity\n",
                "    cosSimilarities = cosine_similarity(img_features, features)\n",
                "\n",
                "    print(\"-----------------------------------------------------------------------\")\n",
                "    print(\"original product:\")\n",
                "    original = load_img(img_path, target_size=(\n",
                "        224, 224))\n",
                "    plt.imshow(original)\n",
                "    plt.show()\n",
                "    print(\"-----------------------------------------------------------------------\")\n",
                "    print(\"most similar products:\")\n",
                "    # get the indexes of the closest images\n",
                "    closest_imgs_indexes = cosSimilarities.argsort()[0][-nb_closest_images:]\n",
                "    # similarity score of the closest images\n",
                "    closest_imgs_similarities = cosSimilarities[0][closest_imgs_indexes]\n",
                "\n",
                "    # get the closest images\n",
                "    closest_imgs = [shopfiles[i]\n",
                "                    for i in closest_imgs_indexes if i < len(shopfiles)]\n",
                "    for i in range(0, nb_closest_images):\n",
                "\n",
                "        original = load_img(closest_imgs[i], target_size=(\n",
                "            224, 224))\n",
                "        plt.imshow(original)\n",
                "        plt.show()\n",
                "        print(\"similarity score:\", closest_imgs_similarities[i])\n",
                "    return 0\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.4"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "e5d44d20471fed6b31c84e96a507e39677b7979bf00486c2e6552218c91082f0"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
